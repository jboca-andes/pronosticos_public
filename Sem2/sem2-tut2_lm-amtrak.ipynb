{"cells":[{"cell_type":"code","execution_count":28,"metadata":{"_execution_state":"idle","_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","execution":{"iopub.execute_input":"2022-08-26T17:24:19.184529Z","iopub.status.busy":"2022-08-26T17:24:19.182879Z","iopub.status.idle":"2022-08-26T17:24:19.206887Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# This R environment comes with many helpful analytics packages installed\n","# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n","# For example, here's a helpful package to load\n","\n","library(tidyverse) # metapackage of all tidyverse packages\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","list.files(path = \"../input\")\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Tutorial de Modelos de Regresión Lineal Múltiple"]},{"cell_type":"markdown","metadata":{},"source":["En este tutorial conocerás cómo adaptar modelos lineales a series de tiempo que presentan componentes estructurales tales como tendencia, estacionalidad y ruido. Particulamente, aprenderás a generar las estructuras de dependencia que conforman los features o variables explicativas más importantes del modelo, ingresarlos a una función típica de regresión lineal y obtener resultados. Usaremos una base de datos que ayuda a ejemplificar el uso de las diferentes paqueterías y funciones contempladas en este tutorial. Esta base es la base de datos de Amtrak, famosa por ser usada en una competencia de kaggle [1](#0)\n","\n","El contenido de este tutorial está organizado de la siguiente manera. En la primera parte, generaremos un modelo con la paquetería de tslm(), donde partiremos de la importación de paqueterías y datos necesarios; aquí, modelaremos paso a paso cada uno de los componentes de la serie. En la segunda parte del tutorial, emplearemos una función básica de regresión lineal, la lm() para modelar las estructuras de la serie. En la tercera parte, aplicaremos la paquetería de ModelTime para el modelamiento, el cual genera otra manera de análisis y predicción de la series. En cada uno de estas partes, generaremos el pronóstico a futuro.\n","\n","**Contenido**\n","1. [Modelación con función tslm()](#1) \n","    1. [Importación de librerías requeridas](#2)\n","    1. [Importación de datos](#3)\n","    1. [Indexado de fecha y visualización](#4)\n","    1. [Identificación de features](#5)\n","    1. [Partición de datos de entrenamiento y prueba](#6)\n","    1. [Especificación del modelo de tendencia](#7)\n","    1. [Especificación del modelo de tendencia polinómica](#8)\n","    1. [Especificaciónd el modelo con estacionalidad](#9)\n","    1. [Especificación del modelo con todos los componentes](#10)\n","    1. [Obtención de métricas de error](#11)\n","    1. [Generación del pronóstico hacia adelante](#12)\n","1. [Modelación con función lm()](#13)\n","    1. [Importación de datos](#14)\n","    1. [Partición de datos de entrenamiento y prueba](#15)\n","    1. [Especificación del modelo lineal con lm()](#16)\n","    1. [Predicción con datos de prueba](#17)\n","    1. [Obtención de métricas de error](#18)\n","    1. [Generación del pronóstico hacia adelante](#19)\n","1. [Modelación con TimeModel()](#20)\n","    1. [Partición de datos en entrenamiento y prueba](#21)\n","    1. [Especificaicón del modelo lineal](#22)\n","    1. [Adición del modelo de ajuste a Model Table](#23)\n","    1. [Calibración y obtención de métricas de error](#24)\n","    1. [Generación del pronóstico hacia adelante](#25)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"1\"></a> <br>\n","## 1. Modelación con función tslm()\n","\n","Comenzaremos este tutorial empleando la función de tslm() a la serie. Como verás, iremos generando modelos que contemplan los diferentes componentes de las series, para termiar con uno que incluye todos los componentes: tendencia lineal, polinómica y estacionalidades."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"2\"></a> <br>\n","## A. Importación de librerías requeridas\n","\n","La importación incluye paquetes para el modelado de los datos, el manejo de las series y la visualización."]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:19.210859Z","iopub.status.busy":"2022-08-26T17:24:19.209353Z","iopub.status.idle":"2022-08-26T17:24:19.240846Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["library(forecast)\n","library(fpp3)\n","library(tidymodels)\n","library(modeltime)\n","library(tidyverse)\n","library(lubridate)\n","library(timetk)\n","library(tsfeatures)\n","library(TSstudio)\n","interactive <- TRUE\n","options(warn = - 1) "]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"3\"></a> <br>\n","### B. Importación de datos\n","La importación de datos la debes realizar a manera que subas el archivo llamado \"Amtrak_data.csv\", disponible en Github y en la plataforma. Su importación dependerá de tu perfil, si es público o privado. Si es privado, deberás contar con espacio disponible."]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:19.244780Z","iopub.status.busy":"2022-08-26T17:24:19.243353Z","iopub.status.idle":"2022-08-26T17:24:19.275945Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["#Importar el data.csv\n","df<-read.csv(\"../input/amtrakcsv/Amtrak_data.csv\", sep=\";\", header=TRUE)\n","head(df)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"4\"></a> <br>\n","### C. Indexado de fecha y visualización\n","\n","Para facilitar las siguientes operaciones, tales de visualización y modelado, debes generar una columna con el formato de fecha, así como el formato particular tipo ts()."]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:19.282180Z","iopub.status.busy":"2022-08-26T17:24:19.279877Z","iopub.status.idle":"2022-08-26T17:24:19.326846Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Creamos columna de fecha, a partir de otra, que es la de Month.\n","df$Date<- as.Date(df$Month, format='%d/%m/%Y')\n","str(df)\n","head(df)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:19.331065Z","iopub.status.busy":"2022-08-26T17:24:19.329669Z","iopub.status.idle":"2022-08-26T17:24:20.915223Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Creamos una visualización.\n","df%>%plot_time_series(Date, Ridership, .interactive = interactive)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:20.920714Z","iopub.status.busy":"2022-08-26T17:24:20.918771Z","iopub.status.idle":"2022-08-26T17:24:20.949676Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Pasamos a formato tipo ts.\n","df.ts=ts(df$Ridership,  start = c(1991,1), end = c(2004, 3), freq = 12)\n","head(df.ts)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"5\"></a> <br>\n","### D. Identificación de features"]},{"cell_type":"markdown","metadata":{},"source":["Para la identificación de features o variables regresores a ingresar al modelo, podemos dar un vistazo a los features más relevantes de los datos, a través de la función tsfeatures(). Igualmente, podemos descomponer la serie para tener una visualización de la tendencia, estacionalidad y finalmente, podemos generar una visualización del comportamiento mensual de la variable de interés.\n","\n"," "]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:20.954673Z","iopub.status.busy":"2022-08-26T17:24:20.952821Z","iopub.status.idle":"2022-08-26T17:24:21.017117Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Veamos los features.\n","tsfeatures(df.ts)"]},{"cell_type":"markdown","metadata":{},"source":["Mediante la función tsfeatures(), podemos observar que la serie posee datos anuales con frecuencia mensual, es decir, frecuencia 12 cada 1 periodo, así como periodos estacionales igualmente mensuales. La linealidad es superior a uno, lo cual es relevante. El nivel de entropia o de dificutad en la predicción, dada la presencia de estructuras complejas en la serie, está por debajo de 1. Otros features relacionan características más específicas de correlaciones seriales lineales y cuadráticas, pero por el momento, podemos retomar estas comentadas para tener idea de la buena elección en la aplicabilidad de los modelos lineales."]},{"cell_type":"markdown","metadata":{},"source":["Veamos ahora los componentes de la serie, la función \"multiple seasonal time serie decomposition by loess\" o \"mstl\" genera una descompoisción empleando un algoritmo STL (Seasonal Decomposition of Time Series by Loess, que funciona por suavizamientos), donde se permiten estacionalidades múltiples y de manera automaizada llega a la descomposición óptima."]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:21.023586Z","iopub.status.busy":"2022-08-26T17:24:21.021116Z","iopub.status.idle":"2022-08-26T17:24:21.487710Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Descomponenmos con la función mstl y visualizamos los componentes.\n","mstl(df.ts)%>%autoplot()+xlab(\"Month\")"]},{"cell_type":"markdown","metadata":{},"source":["En la gráfica se observa que la tendencia que posee un comportamiento polinómico y su comportamiento mensual \"Seasonal 12\".\n","\n","Otra técnica para visualizar los features relevantes, es mediante la visualización de los datos anuales con frecuencia mensual. Esta gráfica es útil ya que podemos darnos idea de qué meses o rezagos o features serán relevantes en el modelo lineal."]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:21.494381Z","iopub.status.busy":"2022-08-26T17:24:21.491843Z","iopub.status.idle":"2022-08-26T17:24:23.212693Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Otra herramienta de visualización para el comonente de estacionalidad, es mediante la eliminación de la tendencia. Luego, imprimimos la de la estacionalidad.\n","detre= mstl(df.ts)\n","df_detrend <- df.ts - detre[,2]\n","ts_seasonal(df_detrend, type = \"box\")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"6\"></a> <br>\n","### E. Partición de datos de entrenamiento y prueba\n","Partamos la serie en entrenamiento y validación"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.216585Z","iopub.status.busy":"2022-08-26T17:24:23.215157Z","iopub.status.idle":"2022-08-26T17:24:23.382538Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# También podemos usar los tradicionales ACF y PACF.\n","acf(diff(df.ts), 60)\n","pacf(diff(df.ts), 60)"]},{"cell_type":"markdown","metadata":{},"source":["Vemos un patrón estacionario semestral en ACF."]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.386454Z","iopub.status.busy":"2022-08-26T17:24:23.385048Z","iopub.status.idle":"2022-08-26T17:24:23.404400Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Partimos la serie, podemos tomar en porcentaje, o mediante la definición de valores.\n","nValid <- 36\n","nTrain <- length(df.ts) - nValid\n","entren.ts <- window(df.ts, start = c(1991, 1), end = c(1991, nTrain))\n","valid.ts <- window(df.ts, start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid))"]},{"attachments":{"93b4ebf6-7d53-475c-b749-9a2dbe37bae3.png":{"image/png":"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"}},"cell_type":"markdown","metadata":{},"source":["<a id=\"7\"></a> <br>\n","### F. Modelos con tendencia\n","Vamos a aplicar un modelo de regresión lineal simple mediante la función tslm(), estableciendo la variable y y el predictor como la variable de tiempo:\n","\n","![image.png](attachment:93b4ebf6-7d53-475c-b749-9a2dbe37bae3.png)\n","\n","Donde Y_t es el valor de la respuesta en el tiempo t y e es el error estándar o ruido blanco del modelo de regresión. Así, modelaremos tres de los cuatro componentes de las series de tiempo: nivel (beta cero), tendencia (Beta 1), y ruido (e). La estacionalidad no la modelaremos ahorita, sino más adelante."]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.408221Z","iopub.status.busy":"2022-08-26T17:24:23.406813Z","iopub.status.idle":"2022-08-26T17:24:23.442024Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Empleamos la función tslm(). Aquí, aplicamos la función de transformación de Box Cox automática mediante la función de lambda.\n","entren.lm = tslm(entren.ts~trend, lambda=\"auto\")\n","summary(entren.lm)\n","#str(entrena.lm)\n","#train.lm.linear.trend <- tslm(train.ts ~ trend, lambda = 1)  #Si deseáramos aplicar una transformación logarítmica a la serie."]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.445970Z","iopub.status.busy":"2022-08-26T17:24:23.444411Z","iopub.status.idle":"2022-08-26T17:24:23.470182Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# En esta opción, eliminamos la función de transformación de datos con Box Cox. No es muy diferente.\n","entren.lm2 = tslm(entren.ts~trend)\n","summary(entren.lm2)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.475280Z","iopub.status.busy":"2022-08-26T17:24:23.473256Z","iopub.status.idle":"2022-08-26T17:24:23.586212Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Podemos graficar el resultado. Imprimimos primero la serie original y sobreponemos el ajuste.\n","plot(df.ts, xlab=\"Time\", ylab=\"Ridership\", ylim=c(1300,2300), bty=\"l\", col=\"black\")\n","lines(entren.lm$fitted, lwd=2, col=\"red\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"r"}},"outputs":[],"source":["# Actualizamos librerías:\n","library(tsibble)\n","library(fable)\n","library(tidyverse)\n","library(TSstudio)\n","library(MAPA)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.590109Z","iopub.status.busy":"2022-08-26T17:24:23.588678Z","iopub.status.idle":"2022-08-26T17:24:23.744234Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Visualizamos los gráficos:\n","entren.lm.pred = forecast(entren.lm, h=nValid)\n","plot(entren.lm.pred, ylim=c(1300,2600), ylab=\"Ridership\", xlab=\"Time\", bty=\"l\", xlim=c(1991,2006.25), main=\"\", flty=2)\n","axis(1, at=seq(1991,2006,1), labels=format(seq(1991,2006,1)))\n","lines(entren.lm.pred$fitted, lwd=2,col=\"red\")\n","lines(valid.ts)\n","lines(entren.ts)\n","lines(c(2004.25 - 3, 2004.25 - 3), c(0, 3500)) \n","lines(c(2004.25, 2004.25), c(0, 3500))\n","text(1996.25, 2500, \"Entrenamiento\")\n","text(2002.75, 2500, \"Validacion\")\n","text(2005.25, 2500, \"Futuro\")\n","arrows(2004 - 3, 2450, 1991.25, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5 - 3, 2450, 2004, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5, 2450, 2006, 2450, code = 3, length = 0.1, lwd = 1, angle = 30)\n"]},{"cell_type":"markdown","metadata":{},"source":["Si observamos el resultado de la regresión, vemos que dista mucho del comportamiento real. Ante ello, procederemos a incluir una complejidad mayor a la tendencia, así como el resto de los componentes."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"8\"></a> <br>\n","### G. Modelos con tendencia polinómica\n","\n","En esta sección, ingresaremos en el código que la tendencia se comporta cuadráticamente, para tratar de captar mejor su comportamiento."]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.750499Z","iopub.status.busy":"2022-08-26T17:24:23.748159Z","iopub.status.idle":"2022-08-26T17:24:23.775841Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["entren.lm.poli = tslm(entren.ts~trend+I(trend^2))\n","summary(entren.lm.poli)"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.781053Z","iopub.status.busy":"2022-08-26T17:24:23.779434Z","iopub.status.idle":"2022-08-26T17:24:23.942671Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["entren.lm.poli.pred = forecast(entren.lm.poli, h=nValid)\n","plot(entren.lm.pred, ylim=c(1300,2600), ylab=\"Ridership\", xlab=\"Time\", bty=\"l\", xlim=c(1991,2006.25), main=\"\", flty=2)\n","axis(1, at=seq(1991,2006,1), labels=format(seq(1991,2006,1)))\n","lines(entren.lm.pred$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.poli.pred$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.poli.pred$mean, lwd = 2,lty = 3, col=\"lightblue\")\n","lines(valid.ts)\n","lines(entren.ts)\n","lines(c(2004.25 - 3, 2004.25 - 3), c(0, 3500)) \n","lines(c(2004.25, 2004.25), c(0, 3500))\n","text(1996.25, 2500, \"Entrenamiento\")\n","text(2002.75, 2500, \"Validacion\")\n","text(2005.25, 2500, \"Futuro\")\n","arrows(2004 - 3, 2450, 1991.25, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5 - 3, 2450, 2004, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5, 2450, 2006, 2450, code = 3, length = 0.1, lwd = 1, angle = 30)\n"]},{"cell_type":"markdown","metadata":{},"source":["Vemos que este modelo mejoró ante el anterior que sólamente incluía una tendencia lineal. Sin embargo, podemos incluir el componente de estacionalidad, que no ha sido considerado al momento."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"9\"></a> <br>\n","### H. Modelos con estacionalidad\n","\n","Retomaremos el modelo anterior e incluiremos el componente de la estacionalidad, cuyo feature es relevante a partir de la visualización de la descomposición de la sere."]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.948679Z","iopub.status.busy":"2022-08-26T17:24:23.946398Z","iopub.status.idle":"2022-08-26T17:24:23.972221Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["entren.lm.season <-tslm(entren.ts~season)  #notar que season es con minuscula, no es el nombre de la columna del mes.\n","summary(entren.lm.season)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"10\"></a> <br>\n","### I. Modelos con todos los componentes\n","\n","Incluyamos ahora, todos los componentes en el modelo de regresión:"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:23.975915Z","iopub.status.busy":"2022-08-26T17:24:23.974544Z","iopub.status.idle":"2022-08-26T17:24:23.998441Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["entren.lm.compo <-tslm(entren.ts~trend+I(trend^2)+season)  #notar que season es con minúscula, no es el nombre de la columna del mes.\n","summary(entren.lm.compo)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.002203Z","iopub.status.busy":"2022-08-26T17:24:24.000843Z","iopub.status.idle":"2022-08-26T17:24:24.187238Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["#Generamos su visualización:\n","entren.lm.compo.pre = forecast(entren.lm.compo, h=nValid)\n","plot(entren.lm.pred, ylim=c(1300,2600), ylab=\"Ridership\", xlab=\"Time\", bty=\"l\", xlim=c(1991,2006.25), main=\"\", flty=2)\n","axis(1, at=seq(1991,2006,1), labels=format(seq(1991,2006,1)))\n","lines(entren.lm.pred$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.poli.pred$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.poli.pred$mean, lwd = 2,lty = 3, col=\"orange\")\n","lines(entren.lm.compo.pre$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.compo.pre$mean, lwd = 2,lty = 3, col=\"orange\")\n","lines(valid.ts)\n","lines(entren.ts)\n","lines(c(2004.25 - 3, 2004.25 - 3), c(0, 3500)) \n","lines(c(2004.25, 2004.25), c(0, 3500))\n","text(1996.25, 2500, \"Entrenamiento\")\n","text(2002.75, 2500, \"Validacion\")\n","text(2005.25, 2500, \"Futuro\")\n","arrows(2004 - 3, 2450, 1991.25, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5 - 3, 2450, 2004, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5, 2450, 2006, 2450, code = 3, length = 0.1, lwd = 1, angle = 30)\n"]},{"cell_type":"markdown","metadata":{},"source":["Vemos que este último modelo genera un mejor ajuste a los datos. Ante ello, procedemos a la obtención de métricas de error, para conocer la precisión del pronóstico empleando el conjunto de datos de prueba."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"11\"></a> <br>\n","### J. Obtención de métricas de error\n","\n","Ahora, calculemos las métricas de RMSE y MAPE, como ejemplos de métricas de error de escala y porcentual en el pronóstico de los datos de prueba."]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.191029Z","iopub.status.busy":"2022-08-26T17:24:24.189610Z","iopub.status.idle":"2022-08-26T17:24:24.219522Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["#Métricas:\n","library(Metrics)\n","rmse_tslm_poli<-rmse(valid.ts, entren.lm.compo.pre$mean)\n","rmse_tslm_poli\n","mape_tslm_poli<-mape(valid.ts, entren.lm.compo.pre$mean)\n","mape_tslm_poli"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"12\"></a> <br>\n","### K.Generación del pronóstico hacia adelante\n","\n","Para el pronóstico forward o futuro, generamos la función de ajuste a todos los datos de la serie e ingresando todos los componentes de la serie, incluyendo el término cuadrático que resultó ser relevante. Es importante recalcar que en esta situación, no debemos generar los features ya que la función lo genera de manera automática."]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.223738Z","iopub.status.busy":"2022-08-26T17:24:24.222274Z","iopub.status.idle":"2022-08-26T17:24:24.246738Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Aplicamos función tslm()\n","lm_all <-tslm(df.ts~trend+I(trend^2)+season)  #notar que season es con minúscula, no es el nombre de la columna del mes.\n","summary(lm_all)"]},{"cell_type":"markdown","metadata":{},"source":["Como vemos, los resultados son muy similares a los obtenidos por la función de lm(). Generamos entonces, el pronóstico a través de la función forecast(), indicando los pasos a pronosticar. Esto quiere decir que el modelo emplea los últimos 30 datos para generar los 30 datos futuros, aplicados al modelo de regresión."]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.250400Z","iopub.status.busy":"2022-08-26T17:24:24.249052Z","iopub.status.idle":"2022-08-26T17:24:24.441093Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos su visualizaicón:\n","pron_fwd = forecast(lm_all, h=30)\n","plot(entren.lm.pred, ylim=c(1300,2600), ylab=\"Ridership\", xlab=\"Time\", bty=\"l\", xlim=c(1991,2006.25), main=\"\", flty=2)\n","axis(1, at=seq(1991,2006,1), labels=format(seq(1991,2006,1)))\n","lines(entren.lm.pred$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.poli.pred$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.poli.pred$mean, lwd = 2,lty = 3, col=\"orange\")\n","lines(entren.lm.compo.pre$fitted, lwd=2,col=\"red\")\n","lines(entren.lm.compo.pre$mean, lwd = 2,lty = 3, col=\"orange\")\n","lines(pron_fwd$mean, lwd = 2,lty = 3, col=\"pink\") ##Futuro: FWD Forecast\n","lines(valid.ts)\n","lines(entren.ts)\n","lines(c(2004.25 - 3, 2004.25 - 3), c(0, 3500)) \n","lines(c(2004.25, 2004.25), c(0, 3500))\n","text(1996.25, 2500, \"Entrenamiento\")\n","text(2002.75, 2500, \"Validacion\")\n","text(2005.25, 2500, \"Futuro\")\n","arrows(2004 - 3, 2450, 1991.25, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5 - 3, 2450, 2004, 2450, code = 3, length = 0.1, lwd = 1,angle = 30)\n","arrows(2004.5, 2450, 2006, 2450, code = 3, length = 0.1, lwd = 1, angle = 30)"]},{"cell_type":"markdown","metadata":{},"source":["De esta manera, vemos que se obtienen muy buenos resultados a través de la aplicación de esta función.\n","\n","Ahora veamos, otra manera de realizar el modelamiento, que es a través de la función de lm() y porteriormente de ModelTime."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"13\"></a> <br>\n","# Modelación con función lm()"]},{"cell_type":"markdown","metadata":{},"source":["Ahora, probemos un tipo de modelamiento a través de la función lm() tradicional. Para ello, deberemos capturar los features de la serie, usualmente se generan estos a través de funciones de retrasos o lag(), así como la generación de tendencias las cuales van cambiando unidad por unidad. Esta generación de features se va dando a manera de ir formando nuenvas columnas.\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"14\"></a> <br>\n","### A. Importación de datos\n","\n","Incluyo estos pasos ya previamente realizados, pero para facilidad de lectura en el ejercicio, rellamemos a los datos, indexemos la fecha."]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.444894Z","iopub.status.busy":"2022-08-26T17:24:24.443477Z","iopub.status.idle":"2022-08-26T17:24:24.473473Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Importamos los datos:\n","df<-read.csv(\"../input/amtrakcsv/Amtrak_data.csv\", sep=\";\", header=TRUE)\n","head(df)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.477898Z","iopub.status.busy":"2022-08-26T17:24:24.475779Z","iopub.status.idle":"2022-08-26T17:24:24.521459Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# GEneramos la columna de date\n","df$Date<- as.Date(df$Month, format='%d/%m/%Y')\n","str(df)\n","head(df)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.527048Z","iopub.status.busy":"2022-08-26T17:24:24.525071Z","iopub.status.idle":"2022-08-26T17:24:24.570194Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["#Esta librería es útil para la generación de rezagos:\n","library(DataCombine)"]},{"cell_type":"markdown","metadata":{},"source":["Y generamos los features, rezagos correspondientes."]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.575457Z","iopub.status.busy":"2022-08-26T17:24:24.573760Z","iopub.status.idle":"2022-08-26T17:24:24.645503Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos los rezagos:\n","df1 <- slide(df, Var = \"Ridership\", slideBy = -1) \n","df2 <- slide(df1, Var = \"Ridership\", slideBy = -2) \n","df3 <- slide(df2, Var = \"Ridership\", slideBy = -3) \n","df4 <- slide(df3, Var = \"Ridership\", slideBy = -4) \n","df5 <- slide(df4, Var = \"Ridership\", slideBy = -5)\n","df6 <- slide(df5, Var = \"Ridership\", slideBy = -6) %>%na.omit()\n","colnames(df6) <- c(\"Month\", \"Ridership\",\"Season\",\"t\", \"Date\", \"l1\", \"l2\", \"l3\", \"l4\",  \"l5\", \"l6\")\n","tail(df6)"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.649504Z","iopub.status.busy":"2022-08-26T17:24:24.647978Z","iopub.status.idle":"2022-08-26T17:24:24.712707Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Agregamos la tendencia:\n","df6$trend = 1:nrow(df6)\n","df6$trend2 = df6$trend^2\n","#df.ts$trend3 = 1:nrow(df.ts)$trend^3 # si se requiriera una tendencia cúbica\n","str(df6)\n","head(df6)\n","tail(df6)"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.716764Z","iopub.status.busy":"2022-08-26T17:24:24.715224Z","iopub.status.idle":"2022-08-26T17:24:24.728882Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Por facilidad, puedes renombrar el objeto.\n","ldf<-df6"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"15\"></a> <br>\n","### B.Partición datos de entrenamiento y prueba"]},{"cell_type":"markdown","metadata":{},"source":["En esta parte, vamos a considerar el mismo horizonte del pronóstico empleado en el modelo con tslm()."]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.732976Z","iopub.status.busy":"2022-08-26T17:24:24.731472Z","iopub.status.idle":"2022-08-26T17:24:24.780490Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["##h: horizonte pronostico\n","h <- 36\n","ldf_train <- ldf[1:(nrow(ldf) - h), ]\n","ldf_test<- ldf[(nrow(ldf) - h + 1):nrow(ldf), ]\n","tail(ldf_train)\n","head(ldf_test)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"16\"></a> <br>\n","### C. Especificación del modelo lineal con lm()\n","\n","Una vez creada la base de datos con los features, procedemos a emplear la función lm()."]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.784222Z","iopub.status.busy":"2022-08-26T17:24:24.782850Z","iopub.status.idle":"2022-08-26T17:24:24.806464Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["####Modelo de referencia: Modelo lineal\n","lm_ldf <- lm(Ridership ~ l1 + l2  + l3 + l4 +l5 +l6 + trend + trend2, data = ldf_train)\n","summary(lm_ldf)\n","#Vemos que varios features no son relevantes, por ello, depuramos el modelo."]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.810150Z","iopub.status.busy":"2022-08-26T17:24:24.808783Z","iopub.status.idle":"2022-08-26T17:24:24.831016Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["####Modelo depurado:\n","lm_ldf2 <- lm(Ridership ~ l1+l6 + trend + trend2, data = ldf_train)\n","summary(lm_ldf2)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"17\"></a> <br>\n","### D. Predicción con datos prueba\n","\n","En esta sección aplicamos la función de predict(), aplicando el modelo depurado, especificando que es una serie de tiempo con \"ts=TRUE\"."]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.834917Z","iopub.status.busy":"2022-08-26T17:24:24.833359Z","iopub.status.idle":"2022-08-26T17:24:24.879921Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos una columna con los resultados del modelo de predicción  que llamamos \"yhat\".\n","ldf_test$yhat <- predict(lm_ldf2, newdata = ldf_test, ts=TRUE)\n","head(ldf_test)\n","str(ldf_test)"]},{"cell_type":"markdown","metadata":{},"source":["Grafiquemos los resultados empleado la función de plotly, especificando las fechas de estudio mediante la generación de fechas en formato \"as.Date\", indicando qué elementos son de eje \"x\" o fechas y cuáles de \"y\". En el resto de líneas, agregamos los resultados de pronóstico en el conjunto de datos de prueba."]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:24.883669Z","iopub.status.busy":"2022-08-26T17:24:24.882269Z","iopub.status.idle":"2022-08-26T17:24:26.314166Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Llamamos primeramente la librería y procedemos a indicar las características de la visualización.\n","library(plotly)\n","start<-format(as.Date(\"1991-01-01\"),\"%Y-%m-%d\")\n","end<-format(as.Date(\"2004-03-01\"),\"%Y-%m-%d\")\n","plot_ly(x = ldf$Date, y = ldf$Ridership,\n","        type = \"scatter\",\n","        mode = \"line\", \n","        name = \"Actual\") %>% \n","  add_lines(x = ldf_test$Date, y = ldf_test$yhat, name = \"LM\") %>%\n","  layout(title = \"LM Forecast\", yaxis = list(title = \"Ridership @ Los Andes\", range = c(1000, 3000)),\n","         xaxis = list(title = \"Date\", range = c(start, end)))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"18\"></a> <br>\n","### E. Obtención de métricas de error\n","\n","Una vez generado el pronóstico en los datos de prueba, podemos medir la precisión de los resultados mediante métricos de error. Usualmente empleamos métricos de escala y de porcentaje, tales como el RMSE y el MAPE, respectivamente. "]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.317919Z","iopub.status.busy":"2022-08-26T17:24:26.316503Z","iopub.status.idle":"2022-08-26T17:24:26.343986Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Comenzamos con la importación de la librería Metrics.\n","library(Metrics)\n","mape_lm_ldf <- mape(ldf_test$Ridership, ldf_test$yhat)\n","mape_lm_ldf\n","rmse_lm_ldf <- rmse(ldf_test$Ridership, ldf_test$yhat)\n","rmse_lm_ldf"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.347683Z","iopub.status.busy":"2022-08-26T17:24:26.346309Z","iopub.status.idle":"2022-08-26T17:24:26.367361Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Podemos comparar con las métricas obtenidas con tslm():\n","mape_tslm_poli\n","rmse_tslm_poli"]},{"cell_type":"markdown","metadata":{},"source":["El algoritmo de tslm ofrece mejores desempeños."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"19\"></a> <br>\n","### F. Generación de pronóstico hacia adelante\n","Primero, generamos un ajuste a toda la serie para obtener la ecuación model; para ello, debemos generar nuevamente todos los features para el modelo lm(). Posteriormente, aplicamos función predict.lm, que emplea los datos de ajuste para generar el pronóstico."]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.370856Z","iopub.status.busy":"2022-08-26T17:24:26.369511Z","iopub.status.idle":"2022-08-26T17:24:26.392831Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Retomamos los datos iniciales en formato data frame:\n","head(df)"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.396356Z","iopub.status.busy":"2022-08-26T17:24:26.395059Z","iopub.status.idle":"2022-08-26T17:24:26.441175Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos los rezagos a toda la base\n","df1f <- slide(df, Var = \"Ridership\", slideBy = -1) \n","df2f <- slide(df1f, Var = \"Ridership\", slideBy = -2) \n","df3f <- slide(df2f, Var = \"Ridership\", slideBy = -3) \n","df4f <- slide(df3f, Var = \"Ridership\", slideBy = -4) \n","df5f <- slide(df4f, Var = \"Ridership\", slideBy = -5)\n","df6f <- slide(df5f, Var = \"Ridership\", slideBy = -6) %>%na.omit()\n","colnames(df6f) <- c(\"Month\", \"Ridership\",\"Season\",\"t\", \"Date\", \"l1\", \"l2\", \"l3\", \"l4\",  \"l5\", \"l6\")\n"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.444813Z","iopub.status.busy":"2022-08-26T17:24:26.443480Z","iopub.status.idle":"2022-08-26T17:24:26.490329Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos los features de tendencia lineal y cuadrática.\n","tail(df6f)\n","df6f$trend = 1:nrow(df6f)\n","df6f$trend2 = df6f$trend^2\n","#df.ts$trend3 = 1:nrow(df.ts)$trend^3 # si se requiriera un atendencia cúbica\n","str(df6f)\n","#tail(df6f)"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.494071Z","iopub.status.busy":"2022-08-26T17:24:26.492687Z","iopub.status.idle":"2022-08-26T17:24:26.514893Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos el modelo de regresión con lm()\n","lm_df6f<-lm(Ridership ~ l1 + l2  + l3 + l4 +l5 +l6 + trend + trend2, data = df6f)\n","summary(lm_df6f)"]},{"cell_type":"markdown","metadata":{},"source":["Para poder generar pronósticos futuros, se debe aplicar el modelo a una estructura de datos donde se tomen los últimos valores para predecir los futuros. Una vez generados, podemos crear la secuencia de fechas para estos mediante la función seq(), que ayudará a la visualización."]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.518411Z","iopub.status.busy":"2022-08-26T17:24:26.517106Z","iopub.status.idle":"2022-08-26T17:24:26.552133Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos el pronóstico hacia adelante\n","lm_fwd <- predict.lm(lm_df6f, interval = \"prediction\")[118:153,]\n","head(lm_fwd)\n","tail(lm_fwd)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.555689Z","iopub.status.busy":"2022-08-26T17:24:26.554387Z","iopub.status.idle":"2022-08-26T17:24:26.569085Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos la secuencia de fechas a dichos valores\n","starter_df <- data.frame(dates=seq(from=(as.POSIXct(strftime(\"2004-04-01\"))),\n","                               length.out = 36, \n","                               by=\"1 month\"),\n","                     data = lm_fwd)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.572902Z","iopub.status.busy":"2022-08-26T17:24:26.571454Z","iopub.status.idle":"2022-08-26T17:24:26.599832Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Asignamos a esas fechas un formato requerido para el gráfico\n","full_data <- data.frame(dates=seq(from=min(starter_df$dates),\n","to=max(starter_df$dates), by=\"1 month\"),\n","data=rep(NA,NROW(seq(from=min(starter_df$dates),\n","to=max(starter_df$dates), by=\"1 month\"))))\n","\n","full_data[full_data$dates %in% starter_df$dates,] <- starter_df[starter_df$dates %in% full_data$dates,]\n","head(full_data)"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:26.603371Z","iopub.status.busy":"2022-08-26T17:24:26.602062Z","iopub.status.idle":"2022-08-26T17:24:28.226709Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Gráfico:\n","library(plotly)\n","start<-format(as.Date(\"1991-01-01\"),\"%Y-%m-%d\")\n","end<-format(as.Date(\"2005-02-01\"),\"%Y-%m-%d\")\n","plot_ly(x = ldf$Date, y = ldf$Ridership,\n","        type = \"scatter\",\n","        mode = \"line\", \n","        name = \"Actual\") %>% \n","  add_lines(x = ldf_test$Date, y = ldf_test$yhat, name = \"LM\") %>%\n","  add_lines(x = full_data$dates, y = full_data$data, name = \"LM FWD\") %>%\n","  layout(title = \"LM Forecast\", yaxis = list(title = \"Ridership @ Los Andes\", range = c(1000, 3000)),\n","         xaxis = list(title = \"Date\", range = c(start, end)))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"20\"></a> <br>\n","## 3. Modelación con TimeModel()\n","\n","Como es usual en el manejo de funciones que involucran series de tiempo, al aemplear esta paquetería es necesario convertir los datos en formato data frame. Posteriormente, vamos a partir la serie en conjunto de entrenamiento y prueba mediante la función de time_series_split(). Posteriormente, camos a definir modelo para después adicionarlo a un formato de TimeTable. Lo vamos a calibrar que significa que el modelo se va a aplicar a toda la serie y va a generar ajustes al mismo para así obtener el modelo final; posteriormente procederemos con el cálculo de los métricos de error de pronóstico. Finalmente, aplicaremos la función de pronóstico futuro."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"21\"></a> <br>\n","### A. Partición de datos en entrenamiento y prueba\n","\n","Comencemos partiendo la serie. Este paso usualmente debiera ser el que procede a la importación de datos, el cual ya hemos realizado previamente."]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:28.230285Z","iopub.status.busy":"2022-08-26T17:24:28.228969Z","iopub.status.idle":"2022-08-26T17:24:28.418773Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# La función de time_series_split genera en un solo paso, la partición de la serie, especificando el periodo respectivo para la prueba.\n","splits <- df %>%\n","  time_series_split(assess = \"36 months\", cumulative = TRUE)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:28.422405Z","iopub.status.busy":"2022-08-26T17:24:28.420970Z","iopub.status.idle":"2022-08-26T17:24:29.822730Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Podemos visualiar la serie con el conjunto de entrenamiento y de prueba, además, adicionando una lpinea de suavizamiento a la tendecia. \n","# Podemos también solicitar que la visualización sea interactiva o no. En este caso, optamos por interactiva.\n","splits %>%\n","  tk_time_series_cv_plan() %>%\n","  plot_time_series_cv_plan(Date, Ridership, .interactive = TRUE)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"22\"></a> <br>\n","### B.Especificación del modelo lineal\n","\n","En esta parte del proceso, vamos a generar el modelo lineal. En este caso, no es necesaria la generación previa de features en la base de datos, ya que la función fit() del modleo lineal de esta paquetería, los genera automáticamente."]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:29.826536Z","iopub.status.busy":"2022-08-26T17:24:29.825165Z","iopub.status.idle":"2022-08-26T17:24:29.954708Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Especificamos que la fecha sea numérica y que los features se traten como factores. Importante indicar ordered como FALSE para que conserve el ordenamiento de fechas y no de valores.\n","model_fit_lm <- linear_reg() %>%\n","    set_engine(\"lm\") %>%\n","    fit(Ridership ~ as.numeric(Date) + factor(month(Date),ordered = FALSE),\n","        data = training(splits))\n","# model_fit_lm  #Si deseamos observar el resultado del modelo"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-08-01T03:43:46.862365Z","iopub.status.busy":"2022-08-01T03:43:46.860488Z","iopub.status.idle":"2022-08-01T03:43:46.876685Z"}},"source":["<a id=\"23\"></a> <br>\n","### C. Adición del modelo de ajuste a ModelTable\n","\n","Los siguientes pasos serán el adicionar el modelo de ajuste antes creado con todos los datos para generar una calibración del mismo. Este proceso involucra que el modelo anterior sea adicionado a la estructura llamada ModelTime.\n","\n","Este paso hace algunas revisiones básicas para asegurarse que cada uno de los modelos son en sí ajustados a los datos y con ello, se organiza una estructura escalable llamada \"Modeltime Table\", que se usa como parte del proceso de pronóstico."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"24\"></a> <br>\n","### D. Calibración y obtención de métricas de error"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:29.958127Z","iopub.status.busy":"2022-08-26T17:24:29.956849Z","iopub.status.idle":"2022-08-26T17:24:30.106782Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Calibramos:\n","calibration_tbl <- model_fit_lm %>%\n","    modeltime_calibrate(new_data = testing(splits))"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:30.110667Z","iopub.status.busy":"2022-08-26T17:24:30.109248Z","iopub.status.idle":"2022-08-26T17:24:30.374917Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["library(ddpcr)\n","##Nueva Calibración del Modelo con toda la serie\n","calibration_tbl %>%\n","    modeltime_forecast(\n","        new_data    = testing(splits),\n","        actual_data = df) %>% quiet(all = TRUE)"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:30.378642Z","iopub.status.busy":"2022-08-26T17:24:30.377249Z","iopub.status.idle":"2022-08-26T17:24:30.612473Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Generamos la calibración como se indicó a toda la base de datos para generar los métricos de precisión o \"accuracy\". \n","calibration_tbl %>%\n","    modeltime_accuracy() %>%\n","    table_modeltime_accuracy(\n","        .interactive = interactive\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"25\"></a> <br>\n","### E. Generación del pronóstico hacia adelante\n","\n","Una vez obtenido el modelo y los métricos, generamos el pronóstico hacia adelante. En el caso se tuvieran varios modelos de especificación dentro el ModelTime, el pronóstico hacia adelante se realiza con el modelo que generó los menores valores de error."]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2022-08-26T17:24:30.616826Z","iopub.status.busy":"2022-08-26T17:24:30.615332Z","iopub.status.idle":"2022-08-26T17:24:32.548232Z"},"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Retomamos el modelo ajustado, indicamos el horizonte en días. Este es equivalente a los horizontes de los modelos tipo tslm() y lm()\n","refit_tbl <- calibration_tbl %>%\n","    modeltime_refit(data = df)\n","refit_tbl %>%\n","    modeltime_forecast(h = \"360 days\", actual_data = df) %>%\n","    plot_modeltime_forecast(\n","      .legend_max_width = 25, \n","      .interactive      = interactive\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["Como podemos observar, el pronóstico hacia adelante generó resultados muy similares a aquellos encontrados mediante las funciones tslm() y lm(). La elección de la paquetería y funciones dependerá tanto de la afinidad del usuario por alguna particular y también, a la facilidad que posee el preprocesamiento de los datos. Es muy común que series que poseen frecuencias diarias y carentes de estacionalidad, no sean buenos candidatos para ser modelados directamente a través de funciones tales como tslm() o la TimeModel; de ahí, la utilidad de la versatilidad de la función lm() que responderá a la creación de los features y modelación que el programador diseñe."]},{"cell_type":"markdown","metadata":{},"source":["En este tutorial, se estudiaron tres diferentes maneras de generar modelos de regresión para el pronóstico en series de tiempo. Empleando la función tslm(), la función lm() y la función de regresión lineal a través de ModelTime().\n","\n","Las funciones de tslm() y de modelo lineal con ModelTime facilitan el proceso de modelado y pronóstico. Estas funciones se desempeñan muy bien cuando las series presentan tendencias significativas, así como frecuencias diferentes a las diarias. Sin embargo, cuando las series presentan frecuencias diarias o carecen de componentes estacionales simples, estas funciones pueden requerir pasos adicionales a las aquí presentadas a menera de poder ser modeladas con dichas funciones. Sin embargo, representan un punto de referencia para la comparación de modelos de regresión y pronóstico."]},{"cell_type":"markdown","metadata":{},"source":["### Referencias:\n","<a id=\"0\"></a> <br>\n","NJ Transit + Amtrak (NEC) Rail Performance- COnsultado el 26 Agosto 2022. Fuente: https://www.kaggle.com/datasets/pranavbadami/nj-transit-amtrak-nec-performance"]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.0.5"}},"nbformat":4,"nbformat_minor":4}
